#!/bin/bash
# Expect base collection path as an argument
BASE_COLLECTION_PATH=$1

# Use PWD as base path if no argument is passed
if [ "${BASE_COLLECTION_PATH}" = "" ]; then
    BASE_COLLECTION_PATH=$(pwd)
fi
  
CEPH_COLLECTION_PATH="${BASE_COLLECTION_PATH}/ceph"
POD_TEMPLATE="/templates/pod.template"

SED_DELIMITER=$(echo -en "\001");
safe_replace () {
    sed "s${SED_DELIMITER}${1}${SED_DELIMITER}${2}${SED_DELIMITER}g"
}


apply_helper_pod() {
    < ${POD_TEMPLATE} safe_replace "NAMESPACE" "$1" | safe_replace "IMAGE_NAME" "$2" | safe_replace "MUST_GATHER" "$HOSTNAME" > pod_helper.yaml
    timeout 120 oc apply -f pod_helper.yaml > /dev/null 2>&1
}

# Inspecting the namespace where ceph-cluster is installed
for ns in $(timeout 120 oc get cephcluster --all-namespaces --no-headers | awk '{print $1}'); do
    CEPH_NS_COLLECTION_PATH=${CEPH_COLLECTION_PATH}/namespaces/${ns}
    echo " -> Fetching dump for ${ns} namespace"

    operatorImage=$(timeout 120 oc get pods -l app=rook-ceph-operator -n openshift-storage -o jsonpath="{range .items[*]}{@.spec.containers[0].image}+{end}" | tr "+" "\n" | head -n1)
    if [ "${operatorImage}" = "" ]; then
        echo "Not able to find the rook's operator image. Skipping collection of ceph command output"  
    else
        apply_helper_pod "$ns" "$operatorImage"
    fi

    # Registering ceph collection scripts for dump collection
    cephblockpools.sh "${CEPH_NS_COLLECTION_PATH}" "${ns}"
    cephclusters.sh "${CEPH_NS_COLLECTION_PATH}" "${ns}"
    cephfilesystems.sh "${CEPH_NS_COLLECTION_PATH}" "${ns}"
    cephobjectstores.sh "${CEPH_NS_COLLECTION_PATH}" "${ns}"
    cephobjectstoreusers.sh "${CEPH_NS_COLLECTION_PATH}" "${ns}"

    # Registering openshift collection scripts for dump collection
    pods.sh "${CEPH_NS_COLLECTION_PATH}" "${ns}"
    configmaps.sh "${CEPH_NS_COLLECTION_PATH}" "${ns}"
    events.sh "${CEPH_NS_COLLECTION_PATH}" "${ns}"
    persistentvolumeclaims.sh "${CEPH_NS_COLLECTION_PATH}" "${ns}"
    secrets.sh "${CEPH_NS_COLLECTION_PATH}" "${ns}"
    services.sh "${CEPH_NS_COLLECTION_PATH}" "${ns}"
    replicationcontrollers.sh "${CEPH_NS_COLLECTION_PATH}" "${ns}"
    deploymentconfigs.sh "${CEPH_NS_COLLECTION_PATH}" "${ns}"
    daemonsets.sh "${CEPH_NS_COLLECTION_PATH}" "${ns}"
    replicasets.sh "${CEPH_NS_COLLECTION_PATH}" "${ns}"
    statefulsets.sh "${CEPH_NS_COLLECTION_PATH}" "${ns}"
    horizontalpodautoscalers.sh "${CEPH_NS_COLLECTION_PATH}" "${ns}"
    cronjobs.sh "${CEPH_NS_COLLECTION_PATH}" "${ns}"
    jobs.sh "${CEPH_NS_COLLECTION_PATH}" "${ns}"
    buildconfigs.sh "${CEPH_NS_COLLECTION_PATH}" "${ns}"
    builds.sh "${CEPH_NS_COLLECTION_PATH}" "${ns}"
    imagestreams.sh "${CEPH_NS_COLLECTION_PATH}" "${ns}"
    routes.sh "${CEPH_NS_COLLECTION_PATH}" "${ns}"
    deployments.sh "${CEPH_NS_COLLECTION_PATH}" "${ns}"
    clusterserviceversion.sh "${CEPH_NS_COLLECTION_PATH}" "${ns}"

    if [ "${operatorImage}" != "" ]; then
        for i in {1..50}
        do
            if [ "$(timeout 120 oc get pods  "${HOSTNAME}"-helper -n "${ns}" -o jsonpath='{.status.phase}')" = "Running" ]; then
                echo " -> Helper pod got deployed successfully for ${ns} namespace"
                break
            fi
            echo " -> Waiting for helper pod to come up in ${ns} namespace. Retrying ${i}"
            sleep 5
        done
        ceph_commands.sh "${CEPH_NS_COLLECTION_PATH}" "${ns}"
        echo " -> Deleting helper pod for ${ns} namespace"
        timeout 120 oc delete -f pod_helper.yaml > /dev/null 2>&1
    fi    
done

